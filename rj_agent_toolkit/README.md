# Model Clients

ğŸ”Œ **ç»Ÿä¸€æ¨¡å‹è°ƒç”¨æ¥å£** - æä¾›ç®€æ´ä¸€è‡´çš„AIæ¨¡å‹è°ƒç”¨æ–¹å¼

[![Python Version](https://img.shields.io/badge/python-3.8+-blue.svg)](https://www.python.org/downloads/)
[![LangChain](https://img.shields.io/badge/LangChain-0.3+-green.svg)](https://github.com/langchain-ai/langchain)

## âœ¨ æ ¸å¿ƒç‰¹æ€§

- **ï¿½ LLMæ¨¡å‹**: æ”¯æŒOllamaæœ¬åœ°éƒ¨ç½²å’Œé€šä¹‰åƒé—®API
- **ï¿½ Embeddingæ¨¡å‹**: æ–‡æœ¬å‘é‡åŒ–ï¼Œæ”¯æŒå¤šç§embeddingæ¨¡å‹
- **ï¿½ï¸ OCRæ¨¡å‹**: å›¾åƒæ–‡å­—è¯†åˆ«ï¼Œæ”¯æŒè¡¨æ ¼è¯†åˆ«
- **âš™ï¸ çµæ´»é…ç½®**: æ‰€æœ‰æ¨¡å‹å¯è‡ªå®šä¹‰é€‰æ‹©ï¼Œæ— ç¡¬ç¼–ç 
- **ï¿½ ç»Ÿä¸€æ¥å£**: ç®€æ´ä¸€è‡´çš„APIè®¾è®¡

## ğŸš€ å¿«é€Ÿå¼€å§‹

### å®‰è£…

```bash
pip install git+https://github.com/Wang-Theo/rj-ai-toolkit.git
```

### åŸºæœ¬ä½¿ç”¨

```python
from rj_agent_toolkit.model_clients import (
    call_ollama_llm,
    get_ollama_embedding,
    call_ollama_ocr
)

# è°ƒç”¨æœ¬åœ°LLM
response = call_ollama_llm(
    system_prompt="ä½ æ˜¯ä¸€ä¸ªä¸“ä¸šåŠ©æ‰‹",
    user_input="ä»€ä¹ˆæ˜¯æœºå™¨å­¦ä¹ ï¼Ÿ",
    model="qwen3:8b"
)

# æ–‡æœ¬å‘é‡åŒ–
vector = get_ollama_embedding(
    text="è¿™æ˜¯ä¸€æ®µæµ‹è¯•æ–‡æœ¬",
    model="bge-m3:latest"
)

# å›¾ç‰‡æ–‡å­—è¯†åˆ«
text = call_ollama_ocr(
    image_path="document.png",
    model="qwen2.5vl:7b"
)
```

## ğŸ“š è¯¦ç»†æ–‡æ¡£

è¯¦ç»†ä½¿ç”¨è¯´æ˜è¯·æŸ¥çœ‹ï¼š[Model Clients å®Œæ•´æ–‡æ¡£](./model_clients/README.md)

## ğŸ› ï¸ åŠŸèƒ½æ¨¡å—

### LLM æ¨¡å‹

- **call_ollama_llm**: è°ƒç”¨æœ¬åœ° Ollama éƒ¨ç½²çš„å¤§è¯­è¨€æ¨¡å‹
- **call_qwen_llm_api**: è°ƒç”¨é€šä¹‰åƒé—® API

### Embedding æ¨¡å‹

- **get_ollama_embedding**: æ–‡æœ¬å‘é‡åŒ–

### OCR æ¨¡å‹

- **call_ollama_ocr**: å›¾ç‰‡æ–‡å­—è¯†åˆ«

## ğŸ”§ ç¯å¢ƒé…ç½®

### Ollama æœåŠ¡

```bash
# å¯åŠ¨ Ollama æœåŠ¡
ollama serve

# æ‹‰å–æ‰€éœ€æ¨¡å‹
ollama pull qwen3:8b
ollama pull bge-m3:latest
ollama pull qwen2.5vl:7b
```

### é€šä¹‰åƒé—® API

```bash
# Windows
set DASHSCOPE_API_KEY=your-api-key

# Linux/Mac
export DASHSCOPE_API_KEY=your-api-key
```

## ï¿½ ä½¿ç”¨ç¤ºä¾‹

### LLM æ¨¡å‹è°ƒç”¨

```python
from rj_agent_toolkit.model_clients import call_ollama_llm

response = call_ollama_llm(
    system_prompt="ä½ æ˜¯ä¸€ä¸ªç¼–ç¨‹åŠ©æ‰‹",
    user_input="å¦‚ä½•ä½¿ç”¨Pythonè¯»å–æ–‡ä»¶ï¼Ÿ",
    model="qwen3:8b",
    temperature=0.7
)
print(response)
```

### æ–‡æœ¬å‘é‡åŒ–

```python
from rj_agent_toolkit.model_clients import get_ollama_embedding

# å•ä¸ªæ–‡æœ¬å‘é‡åŒ–
vector = get_ollama_embedding(
    text="è¿™æ˜¯ä¸€æ®µæµ‹è¯•æ–‡æœ¬",
    model="bge-m3:latest"
)
print(f"å‘é‡ç»´åº¦: {len(vector)}")

# æ‰¹é‡å‘é‡åŒ–
texts = ["æ–‡æœ¬1", "æ–‡æœ¬2", "æ–‡æœ¬3"]
vectors = [
    get_ollama_embedding(text, model="bge-m3:latest") 
    for text in texts
]
```

### OCR è¯†åˆ«

```python
from rj_agent_toolkit.model_clients import call_ollama_ocr

# åŸºæœ¬ä½¿ç”¨
text = call_ollama_ocr(
    image_path="document.png",
    model="qwen2.5vl:7b"
)

# è‡ªå®šä¹‰æç¤ºè¯
custom_prompt = "è¯·æå–å›¾ç‰‡ä¸­çš„æ‰€æœ‰ä¸­æ–‡æ–‡å­—ï¼Œä¿æŒåŸå§‹æ ¼å¼"
text = call_ollama_ocr(
    image_path="chinese_doc.jpg",
    model="qwen2.5vl:7b",
    prompt=custom_prompt
)
```

## ğŸ” API å‚è€ƒ

### call_ollama_llm

è°ƒç”¨æœ¬åœ° Ollama éƒ¨ç½²çš„å¤§è¯­è¨€æ¨¡å‹

**å‚æ•°:**
- `system_prompt` (str): ç³»ç»Ÿæç¤ºè¯
- `user_input` (str): ç”¨æˆ·è¾“å…¥
- `model` (str): æ¨¡å‹åç§° **å¿…å¡«**
- `base_url` (str): OllamaæœåŠ¡åœ°å€ï¼Œé»˜è®¤ "http://localhost:11434/v1"
- `temperature` (float): æ¸©åº¦å‚æ•°ï¼Œé»˜è®¤ 0.01

**è¿”å›:** `str` - æ¨¡å‹å›å¤

### get_ollama_embedding

æ–‡æœ¬å‘é‡åŒ–

**å‚æ•°:**
- `text` (str): éœ€è¦è½¬æ¢çš„æ–‡æœ¬
- `model` (str): embeddingæ¨¡å‹åç§° **å¿…å¡«**
- `base_url` (str): OllamaæœåŠ¡åœ°å€ï¼Œé»˜è®¤ "http://localhost:11434"

**è¿”å›:** `List[float]` - æ–‡æœ¬å‘é‡

### call_ollama_ocr

å›¾ç‰‡æ–‡å­—è¯†åˆ«

**å‚æ•°:**
- `image_path` (str): å›¾ç‰‡è·¯å¾„
- `model` (str): OCRæ¨¡å‹åç§° **å¿…å¡«**
- `base_url` (str): OllamaæœåŠ¡åœ°å€ï¼Œé»˜è®¤ "http://localhost:11434"
- `prompt` (str): è‡ªå®šä¹‰æç¤ºè¯ï¼Œé»˜è®¤ None

**è¿”å›:** `str` - è¯†åˆ«çš„æ–‡å­—

## âš ï¸ æ³¨æ„äº‹é¡¹

1. **æ¨¡å‹å‚æ•°å¿…å¡«**: æ‰€æœ‰å‡½æ•°çš„ `model` å‚æ•°éƒ½æ˜¯å¿…å¡«çš„
2. **æœåŠ¡åœ°å€**: é»˜è®¤ä½¿ç”¨æœ¬åœ° Ollama æœåŠ¡
3. **API Key**: é€šä¹‰åƒé—® API éœ€è¦æœ‰æ•ˆçš„ API Key
4. **æ¨¡å‹å…¼å®¹æ€§**: ç¡®ä¿æŒ‡å®šçš„æ¨¡å‹å·²ä¸‹è½½æˆ–å¯ç”¨

## ğŸš€ å®Œæ•´ç¤ºä¾‹

```bash
# è¿è¡Œå®Œæ•´ç¤ºä¾‹
python examples/model_clients_demo.py
```

## ï¿½ æ”¯æŒçš„æ¨¡å‹

### Ollama æœ¬åœ°æ¨¡å‹
- **LLM**: qwen3:8b, llama3:8b, mistralç­‰
- **Embedding**: bge-m3:latest, nomic-embed-textç­‰
- **OCR**: qwen2.5vl:7b, llava:13bç­‰

### é€šä¹‰åƒé—® API
- qwen-max
- qwen-plus
- qwen-turbo

è¯¦ç»†æ¨¡å‹åˆ—è¡¨è¯·å‚è€ƒï¼š
- [Ollama æ¨¡å‹åº“](https://ollama.com/library)
- [é€šä¹‰åƒé—®æ¨¡å‹](https://help.aliyun.com/zh/model-studio/getting-started/models)

---

**Model Clients** - è®©AIæ¨¡å‹è°ƒç”¨æ›´ç®€å• ğŸš€
