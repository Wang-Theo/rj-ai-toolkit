"""
RAG Toolkit å®Œæ•´ç¤ºä¾‹

æ¼”ç¤ºå¦‚ä½•ä½¿ç”¨RAG toolkitè¿›è¡Œæ–‡æ¡£å¤„ç†ã€æ£€ç´¢å’Œé—®ç­”ã€‚
"""

import os
from pathlib import Path
from rag_toolkit import RAGApi
from rag_toolkit.chunker import ChunkConfig, ChunkStrategy
from rag_toolkit.parser import ParseConfig


def main():
    """ä¸»å‡½æ•° - RAGç³»ç»Ÿå®Œæ•´æ¼”ç¤º"""
    print("ğŸš€ RAG Toolkit å®Œæ•´æ¼”ç¤º")
    print("=" * 60)
    
    # 1. åˆå§‹åŒ–RAGç³»ç»Ÿ
    print("1. åˆå§‹åŒ–RAGç³»ç»Ÿ...")
    
    # é…ç½®
    chunk_config = ChunkConfig(
        chunk_size=500,
        chunk_overlap=50,
        add_start_index=True
    )
    
    parse_config = ParseConfig(
        extract_metadata=True,
        preserve_structure=True,
        extract_tables=True
    )
    
    vector_db_config = {
        "persist_directory": "./rag_demo/chroma_db",
        "collection_name": "demo_collection",
        "embeddings": {
            "model_name": "BAAI/bge-small-zh-v1.5",
            "model_kwargs": {"device": "cpu"}
        }
    }
    
    doc_db_config = {
        "db_path": "./rag_demo/documents.db"
    }
    
    # åˆå§‹åŒ–RAG API
    rag = RAGApi(
        vector_db_config=vector_db_config,
        doc_db_config=doc_db_config,
        chunk_config=chunk_config
    )
    
    print("âœ… RAGç³»ç»Ÿåˆå§‹åŒ–å®Œæˆ")
    
    # 2. åˆ›å»ºç¤ºä¾‹æ–‡æ¡£
    print("\n2. åˆ›å»ºç¤ºä¾‹æ–‡æ¡£...")
    demo_dir = Path("./rag_demo/documents")
    demo_dir.mkdir(parents=True, exist_ok=True)
    
    # åˆ›å»ºç¤ºä¾‹æ–‡æœ¬æ–‡ä»¶
    sample_docs = {
        "äººå·¥æ™ºèƒ½æ¦‚è¿°.txt": """
äººå·¥æ™ºèƒ½ï¼ˆArtificial Intelligenceï¼ŒAIï¼‰æ˜¯è®¡ç®—æœºç§‘å­¦çš„ä¸€ä¸ªé‡è¦åˆ†æ”¯ã€‚
å®ƒè¯•å›¾ç†è§£æ™ºèƒ½çš„å®è´¨ï¼Œå¹¶ç”Ÿäº§å‡ºä¸€ç§æ–°çš„èƒ½ä»¥äººç±»æ™ºèƒ½ç›¸ä¼¼çš„æ–¹å¼åšå‡ºååº”çš„æ™ºèƒ½æœºå™¨ã€‚

AIçš„ä¸»è¦åº”ç”¨é¢†åŸŸåŒ…æ‹¬ï¼š
1. æœºå™¨å­¦ä¹ å’Œæ·±åº¦å­¦ä¹ 
2. è‡ªç„¶è¯­è¨€å¤„ç†
3. è®¡ç®—æœºè§†è§‰
4. è¯­éŸ³è¯†åˆ«å’Œåˆæˆ
5. ä¸“å®¶ç³»ç»Ÿ

å½“å‰ï¼Œäººå·¥æ™ºèƒ½æŠ€æœ¯æ­£åœ¨å¿«é€Ÿå‘å±•ï¼Œåœ¨åŒ»ç–—ã€é‡‘èã€æ•™è‚²ã€äº¤é€šç­‰å¤šä¸ªé¢†åŸŸéƒ½æœ‰é‡è¦åº”ç”¨ã€‚
""",
        
        "æœºå™¨å­¦ä¹ åŸºç¡€.txt": """
æœºå™¨å­¦ä¹ æ˜¯äººå·¥æ™ºèƒ½çš„ä¸€ä¸ªå­é¢†åŸŸï¼Œå®ƒä½¿è®¡ç®—æœºç³»ç»Ÿèƒ½å¤Ÿè‡ªåŠ¨å­¦ä¹ å’Œæ”¹è¿›ï¼Œè€Œæ— éœ€æ˜ç¡®çš„ç¼–ç¨‹ã€‚

ä¸»è¦çš„æœºå™¨å­¦ä¹ ç±»å‹ï¼š
1. ç›‘ç£å­¦ä¹ ï¼šä½¿ç”¨æ ‡è®°æ•°æ®è®­ç»ƒæ¨¡å‹
2. æ— ç›‘ç£å­¦ä¹ ï¼šä»æ— æ ‡è®°æ•°æ®ä¸­å‘ç°æ¨¡å¼
3. å¼ºåŒ–å­¦ä¹ ï¼šé€šè¿‡ä¸ç¯å¢ƒäº¤äº’å­¦ä¹ æœ€ä¼˜ç­–ç•¥

å¸¸ç”¨çš„æœºå™¨å­¦ä¹ ç®—æ³•åŒ…æ‹¬ï¼š
- çº¿æ€§å›å½’å’Œé€»è¾‘å›å½’
- å†³ç­–æ ‘å’Œéšæœºæ£®æ—
- æ”¯æŒå‘é‡æœºï¼ˆSVMï¼‰
- ç¥ç»ç½‘ç»œå’Œæ·±åº¦å­¦ä¹ 
- K-meansèšç±»ç®—æ³•

æœºå™¨å­¦ä¹ åœ¨æ¨èç³»ç»Ÿã€å›¾åƒè¯†åˆ«ã€è¯­éŸ³å¤„ç†ç­‰é¢†åŸŸæœ‰å¹¿æ³›åº”ç”¨ã€‚
""",
        
        "æ·±åº¦å­¦ä¹ æŠ€æœ¯.txt": """
æ·±åº¦å­¦ä¹ æ˜¯æœºå™¨å­¦ä¹ çš„ä¸€ä¸ªé‡è¦åˆ†æ”¯ï¼ŒåŸºäºäººå·¥ç¥ç»ç½‘ç»œè¿›è¡Œå­¦ä¹ ã€‚

æ·±åº¦å­¦ä¹ çš„æ ¸å¿ƒæ¦‚å¿µï¼š
1. ç¥ç»ç½‘ç»œï¼šæ¨¡æ‹Ÿäººè„‘ç¥ç»å…ƒçš„æ•°å­¦æ¨¡å‹
2. åå‘ä¼ æ’­ï¼šè®­ç»ƒç¥ç»ç½‘ç»œçš„å…³é”®ç®—æ³•
3. å·ç§¯ç¥ç»ç½‘ç»œï¼ˆCNNï¼‰ï¼šåœ¨å›¾åƒå¤„ç†ä¸­è¡¨ç°ä¼˜å¼‚
4. å¾ªç¯ç¥ç»ç½‘ç»œï¼ˆRNNï¼‰ï¼šé€‚åˆå¤„ç†åºåˆ—æ•°æ®
5. å˜å‹å™¨ï¼ˆTransformerï¼‰ï¼šåœ¨NLPé¢†åŸŸå–å¾—çªç ´

æ·±åº¦å­¦ä¹ çš„ä¼˜åŠ¿ï¼š
- è‡ªåŠ¨ç‰¹å¾æå–
- å¤„ç†é«˜ç»´æ•°æ®çš„èƒ½åŠ›å¼º
- åœ¨å¤§æ•°æ®ä¸Šæ€§èƒ½ä¼˜å¼‚

æ·±åº¦å­¦ä¹ æ¨åŠ¨äº†è®¡ç®—æœºè§†è§‰ã€è‡ªç„¶è¯­è¨€å¤„ç†ã€è¯­éŸ³è¯†åˆ«ç­‰é¢†åŸŸçš„é‡å¤§çªç ´ã€‚
"""
    }
    
    # å†™å…¥ç¤ºä¾‹æ–‡æ¡£
    for filename, content in sample_docs.items():
        file_path = demo_dir / filename
        with open(file_path, 'w', encoding='utf-8') as f:
            f.write(content)
    
    print(f"âœ… åˆ›å»ºäº† {len(sample_docs)} ä¸ªç¤ºä¾‹æ–‡æ¡£")
    
    # 3. æ‰¹é‡æ·»åŠ æ–‡æ¡£
    print("\n3. æ‰¹é‡æ·»åŠ æ–‡æ¡£åˆ°RAGç³»ç»Ÿ...")
    
    result = rag.add_directory(
        directory_path=demo_dir,
        chunk_strategy=ChunkStrategy.RECURSIVE,
        recursive=False
    )
    
    if result["success"]:
        print(f"âœ… æˆåŠŸå¤„ç† {result['successful_documents']} ä¸ªæ–‡æ¡£")
        print(f"   æ€»å…±åˆ›å»º {result['total_chunks']} ä¸ªæ–‡æ¡£å—")
    else:
        print(f"âŒ å¤„ç†æ–‡æ¡£å¤±è´¥: {result['error']}")
        return
    
    # 4. æœç´¢æ¼”ç¤º
    print("\n4. æœç´¢æ¼”ç¤º...")
    
    queries = [
        "ä»€ä¹ˆæ˜¯äººå·¥æ™ºèƒ½ï¼Ÿ",
        "æœºå™¨å­¦ä¹ çš„ä¸»è¦ç±»å‹æœ‰å“ªäº›ï¼Ÿ",
        "æ·±åº¦å­¦ä¹ ä¸ä¼ ç»Ÿæœºå™¨å­¦ä¹ çš„åŒºåˆ«",
        "CNNå’ŒRNNçš„åº”ç”¨åœºæ™¯",
        "äººå·¥æ™ºèƒ½åœ¨å“ªäº›é¢†åŸŸæœ‰åº”ç”¨ï¼Ÿ"
    ]
    
    for i, query in enumerate(queries, 1):
        print(f"\nğŸ” æŸ¥è¯¢ {i}: {query}")
        print("-" * 40)
        
        # å‘é‡æœç´¢
        results = rag.search(
            query=query,
            top_k=3,
            retrieval_method="vector",
            rerank=True
        )
        
        if results:
            print("ğŸ“„ æœç´¢ç»“æœ:")
            for j, result in enumerate(results, 1):
                content = result["content"][:150] + "..." if len(result["content"]) > 150 else result["content"]
                score = result["score"]
                source = result["metadata"].get("file_name", "æœªçŸ¥æ¥æº")
                
                print(f"   {j}. [{source}] (ç›¸å…³åº¦: {score:.3f})")
                print(f"      {content}")
                print()
        else:
            print("   âŒ æœªæ‰¾åˆ°ç›¸å…³ç»“æœ")
    
    # 5. æ··åˆæ£€ç´¢æ¼”ç¤º
    print("\n5. æ··åˆæ£€ç´¢æ¼”ç¤º...")
    
    test_query = "æ·±åº¦å­¦ä¹ çš„åº”ç”¨"
    print(f"ğŸ” æŸ¥è¯¢: {test_query}")
    
    # å¯¹æ¯”ä¸åŒæ£€ç´¢æ–¹æ³•
    vector_results = rag.search(test_query, top_k=3, retrieval_method="vector")
    hybrid_results = rag.search(test_query, top_k=3, retrieval_method="hybrid")
    
    print("ğŸ“Š æ£€ç´¢æ–¹æ³•å¯¹æ¯”:")
    print(f"å‘é‡æ£€ç´¢ç»“æœæ•°: {len(vector_results)}")
    print(f"æ··åˆæ£€ç´¢ç»“æœæ•°: {len(hybrid_results)}")
    
    # 6. è¯­ä¹‰æœç´¢æ¼”ç¤º
    print("\n6. è¯­ä¹‰æœç´¢æ¼”ç¤º...")
    
    semantic_results = rag.semantic_search(
        query="AIæŠ€æœ¯çš„å‘å±•è¶‹åŠ¿",
        top_k=3,
        similarity_threshold=0.5
    )
    
    print(f"ğŸ§  è¯­ä¹‰æœç´¢ç»“æœæ•°: {len(semantic_results)}")
    if semantic_results:
        for i, result in enumerate(semantic_results, 1):
            source = result["metadata"].get("file_name", "æœªçŸ¥")
            score = result["score"]
            print(f"   {i}. {source} (ç›¸ä¼¼åº¦: {score:.3f})")
    
    # 7. ç³»ç»Ÿç»Ÿè®¡ä¿¡æ¯
    print("\n7. ç³»ç»Ÿç»Ÿè®¡ä¿¡æ¯...")
    
    stats = rag.get_statistics()
    print("ğŸ“ˆ RAGç³»ç»Ÿç»Ÿè®¡:")
    print(f"   å¤„ç†æ–‡æ¡£æ•°: {stats['documents_processed']}")
    print(f"   åˆ›å»ºå—æ•°: {stats['chunks_created']}")
    print(f"   å‘é‡æ•°æ®åº“: {stats['vector_db_stats']}")
    print(f"   æ–‡æ¡£æ•°æ®åº“: {stats['doc_db_stats']}")
    
    # 8. å¥åº·æ£€æŸ¥
    print("\n8. ç³»ç»Ÿå¥åº·æ£€æŸ¥...")
    
    health = rag.health_check()
    print(f"ğŸ¥ ç³»ç»ŸçŠ¶æ€: {health['status']}")
    if health['status'] != 'healthy':
        print(f"   é—®é¢˜ç»„ä»¶: {health.get('failed_components', [])}")
    
    print("\nğŸ‰ RAG Toolkit æ¼”ç¤ºå®Œæˆï¼")
    print("\nğŸ’¡ ä½¿ç”¨æç¤º:")
    print("   - å¯ä»¥ç»§ç»­æ·»åŠ æ›´å¤šæ–‡æ¡£åˆ°ç³»ç»Ÿä¸­")
    print("   - å°è¯•ä¸åŒçš„åˆ‡å—ç­–ç•¥å’Œæ£€ç´¢æ–¹æ³•")
    print("   - è°ƒæ•´ç›¸ä¼¼åº¦é˜ˆå€¼æ¥ä¼˜åŒ–æœç´¢æ•ˆæœ")
    print("   - ä½¿ç”¨æ··åˆæ£€ç´¢æ¥æé«˜å‡†ç¡®ç‡")


def advanced_demo():
    """é«˜çº§åŠŸèƒ½æ¼”ç¤º"""
    print("\nğŸ”¬ é«˜çº§åŠŸèƒ½æ¼”ç¤º")
    print("=" * 60)
    
    # æ¼”ç¤ºä¸åŒåˆ‡å—ç­–ç•¥
    from rag_toolkit.chunker import DocumentChunker, ChunkStrategy, ChunkConfig
    
    chunk_config = ChunkConfig(chunk_size=300, chunk_overlap=30)
    chunker = DocumentChunker(config=chunk_config)
    
    sample_text = """
    äººå·¥æ™ºèƒ½æŠ€æœ¯æ­£åœ¨å¿«é€Ÿå‘å±•ã€‚æœºå™¨å­¦ä¹ æ˜¯AIçš„é‡è¦åˆ†æ”¯ã€‚
    æ·±åº¦å­¦ä¹ é€šè¿‡ç¥ç»ç½‘ç»œæ¨¡æ‹Ÿäººè„‘å·¥ä½œæ–¹å¼ã€‚CNNé€‚åˆå›¾åƒå¤„ç†ã€‚
    RNNé€‚åˆåºåˆ—æ•°æ®å¤„ç†ã€‚Transformeråœ¨NLPé¢†åŸŸè¡¨ç°ä¼˜å¼‚ã€‚
    AIåº”ç”¨äºåŒ»ç–—ã€é‡‘èã€æ•™è‚²ç­‰å¤šä¸ªé¢†åŸŸã€‚
    """
    
    print("ğŸ“Š åˆ‡å—ç­–ç•¥å¯¹æ¯”:")
    
    # å¯¹æ¯”ä¸åŒç­–ç•¥
    comparison = chunker.compare_strategies(sample_text)
    
    for strategy, result in comparison.items():
        if "error" not in result:
            print(f"   {strategy}: {result['chunk_count']} å—, å¹³å‡å¤§å°: {result['avg_chunk_size']:.1f}")
        else:
            print(f"   {strategy}: é”™è¯¯ - {result['error']}")


if __name__ == "__main__":
    try:
        main()
        advanced_demo()
    except KeyboardInterrupt:
        print("\nğŸ‘‹ æ¼”ç¤ºå·²ä¸­æ–­")
    except Exception as e:
        print(f"\nâŒ æ¼”ç¤ºè¿‡ç¨‹ä¸­å‡ºç°é”™è¯¯: {e}")
        print("è¯·æ£€æŸ¥ä¾èµ–æ˜¯å¦æ­£ç¡®å®‰è£…ï¼š")
        print("pip install -r requirements.txt")
