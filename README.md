# RJ AI Toolkit

ğŸš€ **ä¼ä¸šçº§AIå·¥å…·åŒ…é›†åˆ** - åŒ…å«Agentã€RAGç­‰å¤šç§AIå¼€å‘å·¥å…·çš„å®Œæ•´è§£å†³æ–¹æ¡ˆ

[![Python Version](https://img.shields.io/badge/python-3.8+-blue.svg)](https://www.python.org/downloads/)
[![License: MIT](https://img.shields.io/badge/License-MIT-yellow.svg)](https://opensource.org/licenses/MIT)
[![Package Version](https://img.shields.io/badge/version-0.1.0-green.svg)](https://github.com/Wang-Theo/rj-ai-toolkit)

## ğŸ“¦ å·¥å…·åŒ…æ¦‚è§ˆ

RJ AI Toolkit æ˜¯ä¸€ä¸ªä¼ä¸šçº§AIå¼€å‘å·¥å…·åŒ…é›†åˆï¼Œæä¾›äº†å¼€å‘æ™ºèƒ½åº”ç”¨æ‰€éœ€çš„æ ¸å¿ƒç»„ä»¶ã€‚æ¯ä¸ªå·¥å…·åŒ…éƒ½å¯ä»¥ç‹¬ç«‹ä½¿ç”¨ï¼Œä¹Ÿå¯ä»¥ç»„åˆä½¿ç”¨æ¥æ„å»ºå¤æ‚çš„AIåº”ç”¨ã€‚

### ğŸ¤– [ChatAgent](./rj_agent_toolkit/agents/README_AGENT.md)
**æ™ºèƒ½å¯¹è¯ä»£ç†**
- **å¯¹è¯ç®¡ç†**: æŒä¹…åŒ–å¯¹è¯å†å²ï¼Œæ”¯æŒå¤šè½®å¯¹è¯
- **å·¥å…·è°ƒç”¨**: è‡ªåŠ¨è°ƒç”¨å·¥å…·å®Œæˆå¤æ‚ä»»åŠ¡
- **PromptManager**: ç®¡ç† system promptï¼Œæ”¯æŒå¤šç”¨æˆ·å¤šåœºæ™¯
- **ToolManager**: åŒå±‚ç®¡ç†å·¥å…·å’Œå·¥å…·é›†ï¼Œè‡ªåŠ¨æå– LangChain å…ƒæ•°æ®
- **LangChainé›†æˆ**: åŸºäºLangChainå’ŒLangGraphæ„å»º

### ğŸ”Œ [Model Clients](./rj_agent_toolkit/README.md)
**ç»Ÿä¸€æ¨¡å‹è°ƒç”¨æ¥å£**
- **LLMæ¨¡å‹**: æ”¯æŒOllamaæœ¬åœ°éƒ¨ç½²ã€é€šä¹‰åƒé—®API
- **Embeddingæ¨¡å‹**: æ–‡æœ¬å‘é‡åŒ–ï¼Œæ”¯æŒå¤šç§embeddingæ¨¡å‹
- **OCRæ¨¡å‹**: å›¾åƒæ–‡å­—è¯†åˆ«ï¼Œæ”¯æŒè¡¨æ ¼è¯†åˆ«
- **çµæ´»é…ç½®**: æ‰€æœ‰æ¨¡å‹å¯è‡ªå®šä¹‰é€‰æ‹©ï¼Œæ— ç¡¬ç¼–ç 
- **ç»Ÿä¸€æ¥å£**: ç®€æ´ä¸€è‡´çš„APIè®¾è®¡

### ğŸ“š [RAG Toolkit](./rj_rag_toolkit/README.md)
**æ£€ç´¢å¢å¼ºç”Ÿæˆå·¥å…·åŒ…**
- æ™ºèƒ½æ–‡æ¡£åˆ‡å—ï¼šé€’å½’åˆ‡å—ã€è¯­ä¹‰åˆ‡å—ã€é‚®ä»¶åˆ‡å—ã€å¹»ç¯ç‰‡åˆ‡å—
- å¤šæ ¼å¼æ–‡æ¡£è§£æï¼šPDFã€DOCXã€EMLã€MSGã€PPTXç­‰ï¼Œæ”¯æŒOCR
- ç»Ÿä¸€å›¾ç‰‡å¤„ç†ï¼šPNGæ ¼å¼ï¼Œç™½åº•æ— é€æ˜ï¼Œå¯é…ç½®DPI
- é«˜æ•ˆå‘é‡æ£€ç´¢ï¼šåŸºäºChromaDBçš„å‘é‡å­˜å‚¨
- æ··åˆæ£€ç´¢ç­–ç•¥ï¼šç»“åˆå‘é‡æ£€ç´¢å’ŒBM25ç®—æ³•
- é€šç”¨é‡æ’åºå™¨ï¼šæ”¯æŒä»»ä½•é‡æ’åºæ¨¡å‹
- å®Œæ•´çš„æ•°æ®åº“ç®¡ç†ï¼šå‘é‡åº“æ“ä½œå’ŒæŸ¥è¯¢

## ğŸš€ å¿«é€Ÿå¼€å§‹

### å®‰è£…

#### ä» GitHub å®‰è£…ï¼ˆæ¨èï¼‰
```bash
pip install git+https://github.com/Wang-Theo/rj-ai-toolkit.git
```

#### ä» GitHub æ›´æ–°
**âš ï¸ é‡è¦ï¼šå¦‚æœä¹‹å‰å®‰è£…è¿‡æ—§ç‰ˆæœ¬ï¼Œå¿…é¡»å…ˆå¸è½½åé‡æ–°å®‰è£…**

```bash
# 1. å¸è½½æ—§ç‰ˆæœ¬ï¼ˆå¿…é¡»ï¼‰
pip uninstall rj-ai-toolkit -y

# 2. å®‰è£…æœ€æ–°ç‰ˆæœ¬
pip install git+https://github.com/Wang-Theo/rj-ai-toolkit.git
```

æˆ–è€…ä½¿ç”¨å¼ºåˆ¶é‡è£…ï¼ˆæ¨èï¼‰ï¼š
```bash
pip install --force-reinstall git+https://github.com/Wang-Theo/rj-ai-toolkit.git
```

#### ä»æºç å®‰è£…
```bash
git clone https://github.com/Wang-Theo/rj-ai-toolkit.git
cd rj-ai-toolkit
pip install -e .
```

#### å®‰è£…ä¾èµ–
```bash
pip install -r requirements.txt
```

### ChatAgent ä½¿ç”¨ç¤ºä¾‹

```python
from rj_agent_toolkit import ChatAgent
from rj_agent_toolkit.model_clients import call_ollama_llm

# åˆ›å»º LLM
llm = call_ollama_llm(model="qwen2.5:7b")

# åˆ›å»º Agent
agent = ChatAgent(
    llm=llm,
    system_prompt="ä½ æ˜¯ä¸€ä¸ªå‹å¥½çš„AIåŠ©æ‰‹"
)

# å¼€å§‹å¯¹è¯
result = agent.chat(
    user_input="ä½ å¥½ï¼Œè¯·ä»‹ç»ä¸€ä¸‹è‡ªå·±",
    thread_id="session-001"
)

print(result['response'])
```

### Model Clients ä½¿ç”¨ç¤ºä¾‹

```python
from rj_agent_toolkit.model_clients import (
    call_ollama_llm,
    get_ollama_embedding,
    call_ollama_ocr
)

# è°ƒç”¨æœ¬åœ°LLM
response = call_ollama_llm(
    system_prompt="ä½ æ˜¯ä¸€ä¸ªä¸“ä¸šåŠ©æ‰‹",
    user_input="ä»€ä¹ˆæ˜¯æœºå™¨å­¦ä¹ ï¼Ÿ",
    model="qwen3:8b"
)

# æ–‡æœ¬å‘é‡åŒ–
vector = get_ollama_embedding(
    text="è¿™æ˜¯ä¸€æ®µæµ‹è¯•æ–‡æœ¬",
    model="bge-m3:latest"
)

# å›¾ç‰‡æ–‡å­—è¯†åˆ«
text = call_ollama_ocr(
    image_path="document.png",
    model="qwen2.5vl:7b"
)
```

### RAG Toolkit ä½¿ç”¨ç¤ºä¾‹

```python
from rj_rag_toolkit import (
    RecursiveChunker,
    PDFParser,
    ChromaManager,
    VectorRetriever,
    Reranker
)
from rj_rag_toolkit.chunker import ChunkConfig

# åˆå§‹åŒ–ç»„ä»¶
chunk_config = ChunkConfig(chunk_size=500, chunk_overlap=50)
chunker = RecursiveChunker(chunk_config)
parser = PDFParser()
db_manager = ChromaManager(
    persist_directory="./vector_db",
    collection_name="my_docs"
)

# è§£æå’Œåˆ‡å—
documents = parser.parse("path/to/document.pdf")
chunks = []
for doc in documents:
    doc_chunks = chunker.chunk_text(doc.page_content, doc.metadata)
    chunks.extend(doc_chunks)

# å­˜å‚¨åˆ°å‘é‡æ•°æ®åº“
db_manager.add_documents(chunks)

# åˆ›å»ºæ£€ç´¢å™¨å¹¶æœç´¢
retriever = VectorRetriever(db_manager)
results = retriever.retrieve(query="æŸ¥è¯¢å†…å®¹", top_k=5)

for result in results:
    print(f"ç›¸å…³åº¦: {result['score']:.3f}")
    print(f"å†…å®¹: {result['content'][:200]}...")
```

## ğŸ“– è¯¦ç»†æ–‡æ¡£

- [ChatAgent è¯¦ç»†æ–‡æ¡£](./rj_agent_toolkit/agents/README_AGENT.md)
- [Model Clients è¯¦ç»†æ–‡æ¡£](./rj_agent_toolkit/README.md)
- [RAG Toolkit è¯¦ç»†æ–‡æ¡£](./rj_rag_toolkit/README.md)

## ğŸ”§ ç¤ºä¾‹ä»£ç 

æŸ¥çœ‹ `examples/` ç›®å½•è·å–å®Œæ•´ç¤ºä¾‹ã€‚

## ğŸ—ï¸ é¡¹ç›®ç»“æ„

```
rj-ai-toolkit/
â”œâ”€â”€ rj_agent_toolkit/              # æ™ºèƒ½å¯¹è¯ä»£ç†å·¥å…·åŒ…
â”‚   â”œâ”€â”€ agents/
â”‚   â”‚   â”œâ”€â”€ chat_agent.py          # ChatAgent å®ç°
â”‚   â”‚   â”œâ”€â”€ prompt_manager.py      # Prompt ç®¡ç†å™¨
â”‚   â”‚   â””â”€â”€ tool_manager.py        # Tool ç®¡ç†å™¨
â”‚   â””â”€â”€ model_clients/             # æ¨¡å‹å®¢æˆ·ç«¯
â”‚       â”œâ”€â”€ llm.py                 # LLM æ¥å£
â”‚       â”œâ”€â”€ embedding.py           # Embedding æ¥å£
â”‚       â””â”€â”€ ocr.py                 # OCR æ¥å£
â”œâ”€â”€ rj_rag_toolkit/                # æ£€ç´¢å¢å¼ºç”Ÿæˆå·¥å…·åŒ…
â”‚   â”œâ”€â”€ chunker/                   # æ–‡æ¡£åˆ‡å—å™¨
â”‚   â”œâ”€â”€ parser/                    # æ–‡æ¡£è§£æå™¨
â”‚   â”œâ”€â”€ db_manager/                # æ•°æ®åº“ç®¡ç†å™¨
â”‚   â”œâ”€â”€ retriever/                 # æ£€ç´¢å™¨
â”‚   â””â”€â”€ reranker/                  # é‡æ’åºå™¨
â””â”€â”€ examples/                      # ä½¿ç”¨ç¤ºä¾‹
```

## âš™ï¸ ç³»ç»Ÿè¦æ±‚

- Python 3.8+
- Ollamaï¼ˆå¯é€‰ï¼Œç”¨äºæœ¬åœ°æ¨¡å‹ï¼‰

## ğŸ”§ é…ç½®è¯´æ˜

ç¯å¢ƒå˜é‡ï¼ˆå¯é€‰ï¼‰ï¼š
```bash
DASHSCOPE_API_KEY=your_key  # é€šä¹‰åƒé—® API
```

Ollama ä½¿ç”¨ï¼š
```bash
ollama serve
ollama pull qwen3:8b
```

## ğŸ¤ æ‰©å±•å¼€å‘

è‡ªå®šä¹‰æ¨¡å‹è°ƒç”¨ï¼š

```python
from rj_agent_toolkit.model_clients import call_ollama_llm

response = call_ollama_llm(
    system_prompt="ä½ æ˜¯ä¸“ä¸šåŠ©æ‰‹",
    user_input="ä½ å¥½",
    model="custom-model:latest",
    base_url="http://your-server:11434/v1",
    temperature=0.8
)
```

è‡ªå®šä¹‰ RAG ç»„ä»¶ï¼š

```python
from rj_rag_toolkit.parser import BaseParser

class CustomParser(BaseParser):
    def _get_supported_extensions(self):
        return ["custom"]
    
    def _parse_file_content(self, file_path):
        return "è‡ªå®šä¹‰è§£æç»“æœ"
```

## ğŸ› æ•…éšœæ’é™¤

å¸¸è§é—®é¢˜ï¼š

1. **Ollama è¿æ¥å¤±è´¥** - ç¡®ä¿æœåŠ¡å·²å¯åŠ¨ï¼š`ollama serve`
2. **ä¾èµ–å®‰è£…** - ä½¿ç”¨è™šæ‹Ÿç¯å¢ƒé¿å…å†²çª
3. **å†…å­˜ä¸è¶³** - ä½¿ç”¨æ›´å°çš„æ¨¡å‹æˆ–è°ƒæ•´æ‰¹å¤„ç†å¤§å°

æŠ€æœ¯æ”¯æŒï¼š
- [æäº¤ Issue](https://github.com/Wang-Theo/rj-ai-toolkit/issues)
- é‚®ç®±ï¼šrenjiewang31@gmail.com

## ğŸ“œ æ›´æ–°æ—¥å¿—

**v0.1.0** (2025-01-21)

- âœ¨ åˆå§‹ç‰ˆæœ¬å‘å¸ƒ
- ğŸ¤– ChatAgent å¯¹è¯ä»£ç†
- ğŸ”Œ Model Clientsï¼ˆLLMã€Embeddingã€OCRï¼‰
- ğŸ“š RAG Toolkit åŸºç¡€åŠŸèƒ½

## ğŸ›£ï¸ å¼€å‘è·¯çº¿å›¾

**çŸ­æœŸè®¡åˆ’**

- [x] ChatAgent æ™ºèƒ½å¯¹è¯ä»£ç†
- [ ] æ›´å¤šå†…ç½®å·¥å…·é›†
- [ ] æ•°æ®åˆ†æå·¥å…·

**ä¸­æœŸè®¡åˆ’**

- [ ] å¤šåª’ä½“å¤„ç†å·¥å…·
- [ ] ç¬¬ä¸‰æ–¹ API é›†æˆ
- [ ] Web å¯è§†åŒ–ç•Œé¢

**é•¿æœŸè®¡åˆ’**

- [ ] æ›´å¤š AI æ¨¡å‹æ”¯æŒ
- [ ] ä¼ä¸šç‰ˆåŠŸèƒ½
- [ ] äº‘ç«¯éƒ¨ç½²æ–¹æ¡ˆ

## ğŸ“„ è®¸å¯è¯

MIT License - è¯¦è§ [LICENSE](LICENSE)

## ğŸ™ è‡´è°¢

- [LangChain](https://github.com/langchain-ai/langchain) - Agent å’Œå·¥å…·æ¡†æ¶
- [LangGraph](https://github.com/langchain-ai/langgraph) - Agent çŠ¶æ€ç®¡ç†
- [Ollama](https://github.com/ollama/ollama) - æœ¬åœ° LLM éƒ¨ç½²
- [ChromaDB](https://github.com/chroma-core/chroma) - å‘é‡æ•°æ®åº“
- [Sentence Transformers](https://github.com/UKPLab/sentence-transformers) - æ–‡æœ¬å‘é‡åŒ–
- [BGE Models](https://github.com/FlagOpen/FlagEmbedding) - ä¸­æ–‡ Embedding æ¨¡å‹

---

**RJ AI Toolkit** - è®© AI å¼€å‘æ›´ç®€å• ğŸš€
