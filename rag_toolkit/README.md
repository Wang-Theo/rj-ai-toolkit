# RAG Toolkit

ğŸ“š **ä¼ä¸šçº§æ£€ç´¢å¢å¼ºç”Ÿæˆå·¥å…·åŒ…** - åŸºäºLangChainçš„æ™ºèƒ½æ–‡æ¡£å¤„ç†å’Œæ£€ç´¢ç³»ç»Ÿ

[![Python Version](https://img.shields.io/badge/python-3.8+-blue.svg)](https://www.python.org/downloads/)
[![LangChain](https://img.shields.io/badge/LangChain-0.3+-green.svg)](https://github.com/langchain-ai/langchain)
[![ChromaDB](https://img.shields.io/badge/ChromaDB-0.4+-blue.svg)](https://github.com/chroma-core/chroma)

## âœ¨ æ ¸å¿ƒç‰¹æ€§

- **ğŸ“„ æ™ºèƒ½åˆ‡å—**: æ”¯æŒé€’å½’åˆ‡å—ã€è¯­ä¹‰åˆ‡å—ç­‰å¤šç§ç­–ç•¥
- **ğŸ—‚ï¸ å¤šæ ¼å¼è§£æ**: PDFã€Wordã€æ–‡æœ¬ã€Markdownç­‰æ–‡æ¡£æ ¼å¼
- **ğŸ” å‘é‡æ£€ç´¢**: åŸºäºBGEç­‰å…ˆè¿›åµŒå…¥æ¨¡å‹çš„è¯­ä¹‰æ£€ç´¢
- **âš¡ æ··åˆæ£€ç´¢**: ç»“åˆå‘é‡æ£€ç´¢å’ŒBM25çš„æ··åˆç­–ç•¥
- **ğŸ¯ æ™ºèƒ½é‡æ’**: ä½¿ç”¨é‡æ’åºæ¨¡å‹æé«˜æ£€ç´¢ç²¾åº¦
- **ğŸ’¾ æ•°æ®ç®¡ç†**: å®Œæ•´çš„æ–‡æ¡£å’Œå‘é‡æ•°æ®åº“ç®¡ç†

## ğŸ—ï¸ ç³»ç»Ÿæ¶æ„

```
RAG Toolkit
â”œâ”€â”€ ğŸ“ Parser (æ–‡æ¡£è§£æå™¨)
â”‚   â”œâ”€â”€ PDFè§£æå™¨
â”‚   â”œâ”€â”€ Wordè§£æå™¨
â”‚   â”œâ”€â”€ æ–‡æœ¬è§£æå™¨
â”‚   â””â”€â”€ Markdownè§£æå™¨
â”œâ”€â”€ âœ‚ï¸ Chunker (åˆ‡å—å™¨)
â”‚   â”œâ”€â”€ é€’å½’åˆ‡å—å™¨
â”‚   â”œâ”€â”€ è¯­ä¹‰åˆ‡å—å™¨
â”‚   â””â”€â”€ æ··åˆåˆ‡å—å™¨
â”œâ”€â”€ ğŸ’¾ DB Manager (æ•°æ®åº“ç®¡ç†å™¨)
â”‚   â”œâ”€â”€ å‘é‡æ•°æ®åº“ (ChromaDB)
â”‚   â””â”€â”€ æ–‡æ¡£æ•°æ®åº“ (SQLite)
â”œâ”€â”€ ğŸ” Retriever (æ£€ç´¢å™¨)
â”‚   â”œâ”€â”€ å‘é‡æ£€ç´¢å™¨
â”‚   â”œâ”€â”€ BM25æ£€ç´¢å™¨
â”‚   â””â”€â”€ æ··åˆæ£€ç´¢å™¨
â”œâ”€â”€ ğŸ¯ Ranker (é‡æ’åºå™¨)
â”‚   â”œâ”€â”€ BGEé‡æ’åºå™¨
â”‚   â””â”€â”€ CrossEncoderé‡æ’åºå™¨
â””â”€â”€ ğŸš€ RAG API (ç»Ÿä¸€æ¥å£)
```

## ğŸš€ å¿«é€Ÿå¼€å§‹

### 1. åŸºæœ¬ä½¿ç”¨
```python
from rag_toolkit import RAGApi
from rag_toolkit.chunker import ChunkConfig, ChunkStrategy

# åˆå§‹åŒ–RAGç³»ç»Ÿ
rag = RAGApi(
    vector_db_config={
        "persist_directory": "./vector_db",
        "collection_name": "my_docs"
    },
    chunk_config=ChunkConfig(chunk_size=500, chunk_overlap=50)
)

# æ·»åŠ æ–‡æ¡£
result = rag.add_document("path/to/document.pdf")
print(f"æ·»åŠ æˆåŠŸï¼Œåˆ›å»ºäº† {result['chunk_count']} ä¸ªæ–‡æ¡£å—")

# æ™ºèƒ½æœç´¢
results = rag.search(
    query="RAGç³»ç»Ÿå¦‚ä½•å·¥ä½œï¼Ÿ",
    top_k=5,
    retrieval_method="hybrid",  # æ··åˆæ£€ç´¢
    rerank=True  # å¯ç”¨é‡æ’åº
)

for result in results:
    print(f"ç›¸å…³åº¦: {result['score']:.3f}")
    print(f"å†…å®¹: {result['content'][:200]}...")
```

### 2. æ‰¹é‡å¤„ç†æ–‡æ¡£
```python
# æ·»åŠ æ•´ä¸ªç›®å½•çš„æ–‡æ¡£
result = rag.add_directory(
    directory_path="./documents",
    chunk_strategy=ChunkStrategy.SEMANTIC,  # ä½¿ç”¨è¯­ä¹‰åˆ‡å—
    recursive=True,  # é€’å½’æœç´¢å­ç›®å½•
    file_pattern="*.pdf"  # åªå¤„ç†PDFæ–‡ä»¶
)

print(f"å¤„ç†äº† {result['successful_documents']} ä¸ªæ–‡æ¡£")
print(f"æ€»å…±åˆ›å»º {result['total_chunks']} ä¸ªæ–‡æ¡£å—")
```

### 3. é«˜çº§é…ç½®
```python
from rag_toolkit.chunker import ChunkConfig, ChunkStrategy
from rag_toolkit.parser import ParseConfig

# åˆ‡å—é…ç½®
chunk_config = ChunkConfig(
    chunk_size=1000,           # å—å¤§å°
    chunk_overlap=100,         # é‡å å¤§å°
    separators=["\n\n", "\n", "ã€‚", "ï¼", "ï¼Ÿ"],  # åˆ†éš”ç¬¦
    add_start_index=True       # æ·»åŠ ä½ç½®ç´¢å¼•
)

# è§£æé…ç½®
parse_config = ParseConfig(
    extract_metadata=True,     # æå–å…ƒæ•°æ®
    preserve_structure=True,   # ä¿ç•™æ–‡æ¡£ç»“æ„
    extract_tables=True,       # æå–è¡¨æ ¼
    extract_images=False       # ä¸æå–å›¾ç‰‡
)

# å‘é‡æ•°æ®åº“é…ç½®
vector_db_config = {
    "persist_directory": "./chroma_db",
    "collection_name": "enterprise_docs",
    "embeddings": {
        "model_name": "BAAI/bge-large-zh-v1.5",  # ä½¿ç”¨å¤§æ¨¡å‹
        "model_kwargs": {"device": "cuda"}        # GPUåŠ é€Ÿ
    }
}

# åˆå§‹åŒ–é«˜çº§RAGç³»ç»Ÿ
rag = RAGApi(
    vector_db_config=vector_db_config,
    chunk_config=chunk_config
)
```

## ğŸ“Š åˆ‡å—ç­–ç•¥å¯¹æ¯”

### é€’å½’åˆ‡å—
```python
from rag_toolkit.chunker import DocumentChunker, ChunkStrategy

chunker = DocumentChunker(strategy=ChunkStrategy.RECURSIVE)
chunks = chunker.chunk_text(text)
# ç‰¹ç‚¹ï¼šå¿«é€Ÿã€ç¨³å®šï¼Œé€‚åˆå¤§å¤šæ•°åœºæ™¯
```

### è¯­ä¹‰åˆ‡å—
```python
chunker = DocumentChunker(strategy=ChunkStrategy.SEMANTIC)
chunks = chunker.chunk_text(text)
# ç‰¹ç‚¹ï¼šä¿æŒè¯­ä¹‰å®Œæ•´æ€§ï¼Œé€‚åˆå¤æ‚æ–‡æ¡£
```

### æ··åˆåˆ‡å—
```python
chunks = chunker.chunk_with_hybrid_strategy(text)
# ç‰¹ç‚¹ï¼šç»“åˆä¸¤ç§ç­–ç•¥çš„ä¼˜åŠ¿
```

### è‡ªåŠ¨ç­–ç•¥é€‰æ‹©
```python
chunks = chunker.chunk_with_auto_strategy(text)
# ç‰¹ç‚¹ï¼šè‡ªåŠ¨é€‰æ‹©æœ€ä½³ç­–ç•¥
```

## ğŸ” æ£€ç´¢ç­–ç•¥

### å‘é‡æ£€ç´¢
```python
results = rag.search(
    query="æŸ¥è¯¢å†…å®¹",
    retrieval_method="vector",
    top_k=10
)
# ç‰¹ç‚¹ï¼šè¯­ä¹‰ç›¸ä¼¼åº¦æ£€ç´¢ï¼Œç†è§£æŸ¥è¯¢æ„å›¾
```

### æ··åˆæ£€ç´¢
```python
results = rag.search(
    query="æŸ¥è¯¢å†…å®¹",
    retrieval_method="hybrid",
    top_k=10
)
# ç‰¹ç‚¹ï¼šç»“åˆè¯­ä¹‰å’Œå…³é”®è¯æ£€ç´¢
```

### è¯­ä¹‰æœç´¢
```python
results = rag.semantic_search(
    query="æŸ¥è¯¢å†…å®¹",
    similarity_threshold=0.7,  # ç›¸ä¼¼åº¦é˜ˆå€¼
    top_k=5
)
# ç‰¹ç‚¹ï¼šé«˜ç²¾åº¦è¯­ä¹‰åŒ¹é…
```

## ğŸ¯ é‡æ’åºåŠŸèƒ½

### å¯ç”¨é‡æ’åº
```python
# ä½¿ç”¨é»˜è®¤é‡æ’åºå™¨
results = rag.search(query="æŸ¥è¯¢", rerank=True)

# æ‰‹åŠ¨é‡æ’åº
from rag_toolkit.ranker import BGERanker
ranker = BGERanker()
reranked_results = ranker.rerank(query, results, top_k=5)
```

## ğŸ“ æ”¯æŒçš„æ–‡æ¡£æ ¼å¼

| æ ¼å¼ | æ‰©å±•å | è§£æå™¨ | ç‰¹æ®ŠåŠŸèƒ½ |
|------|--------|--------|----------|
| PDF | .pdf | PDFParser | âœ… å…ƒæ•°æ®æå–ã€åˆ†é¡µä¿¡æ¯ |
| Word | .docx, .doc | WordParser | âœ… è¡¨æ ¼æå–ã€æ ·å¼ä¿ç•™ |
| æ–‡æœ¬ | .txt | TextParser | âœ… ç¼–ç è‡ªåŠ¨æ£€æµ‹ |
| Markdown | .md | MarkdownParser | âœ… ç»“æ„ä¿ç•™ã€è¯­æ³•è§£æ |

## ğŸ”§ è‡ªå®šä¹‰ç»„ä»¶

### è‡ªå®šä¹‰è§£æå™¨
```python
from rag_toolkit.parser import BaseParser

class CustomParser(BaseParser):
    def _get_supported_extensions(self):
        return ["custom"]
    
    def _parse_file_content(self, file_path):
        # å®ç°è‡ªå®šä¹‰è§£æé€»è¾‘
        return "è§£æåçš„æ–‡æœ¬å†…å®¹"

# æ³¨å†Œè‡ªå®šä¹‰è§£æå™¨
parser.add_parser(["custom"], CustomParser())
```

### è‡ªå®šä¹‰åˆ‡å—å™¨
```python
from rag_toolkit.chunker import BaseChunker

class CustomChunker(BaseChunker):
    def chunk_text(self, text, metadata=None):
        # å®ç°è‡ªå®šä¹‰åˆ‡å—é€»è¾‘
        return chunks
```

## ğŸ’¾ æ•°æ®ç®¡ç†

### æ•°æ®åº“ç»Ÿè®¡
```python
# è·å–ç³»ç»Ÿç»Ÿè®¡ä¿¡æ¯
stats = rag.get_statistics()
print(f"æ–‡æ¡£æ•°é‡: {stats['documents_processed']}")
print(f"æ–‡æ¡£å—æ•°: {stats['chunks_created']}")
```

### å¥åº·æ£€æŸ¥
```python
# ç³»ç»Ÿå¥åº·æ£€æŸ¥
health = rag.health_check()
print(f"ç³»ç»ŸçŠ¶æ€: {health['status']}")
```

### æ•°æ®æ¸…ç†
```python
# åˆ é™¤ç‰¹å®šæ–‡æ¡£
rag.delete_document(doc_id)

# æ¸…ç©ºæ‰€æœ‰æ•°æ®
rag.clear_all()
```

## ğŸ“Š æ€§èƒ½ä¼˜åŒ–

### å‘é‡æ•°æ®åº“ä¼˜åŒ–
```python
# ä½¿ç”¨GPUåŠ é€Ÿ
vector_config = {
    "embeddings": {
        "model_kwargs": {"device": "cuda"}
    }
}

# æ‰¹é‡å¤„ç†
results = rag.add_documents(file_paths, batch_size=20)
```

### æ£€ç´¢ä¼˜åŒ–
```python
# è®¾ç½®è¿‡æ»¤æ¡ä»¶
results = rag.search(
    query="æŸ¥è¯¢",
    filters={"source": "é‡è¦æ–‡æ¡£", "date": "2024"},
    top_k=10
)
```

## ğŸ§ª ç¤ºä¾‹ä»£ç 

### è¿è¡Œå®Œæ•´ç¤ºä¾‹
```bash
# RAGå¿«é€Ÿå¼€å§‹
python examples/rag_examples/quick_start.py

# RAGå®Œæ•´åŠŸèƒ½æ¼”ç¤º  
python examples/rag_examples/complete_rag_demo.py
```

### åŸºç¡€ç¤ºä¾‹
```python
# å‚è€ƒ examples/rag_examples/ ç›®å½•ä¸‹çš„ç¤ºä¾‹ä»£ç 
```

## ğŸ”§ æ•…éšœæ’é™¤

### å¸¸è§é—®é¢˜

1. **å‘é‡æ•°æ®åº“è¿æ¥å¤±è´¥**
   ```python
   # æ£€æŸ¥ChromaDBæ˜¯å¦æ­£ç¡®å®‰è£…
   pip install chromadb
   ```

2. **æ–‡æ¡£è§£æå¤±è´¥**
   ```python
   # å®‰è£…å¯¹åº”çš„è§£æåº“
   pip install PyMuPDF python-docx
   ```

3. **åµŒå…¥æ¨¡å‹ä¸‹è½½æ…¢**
   ```python
   # é…ç½®å›½å†…é•œåƒæº
   import os
   os.environ["HF_ENDPOINT"] = "https://hf-mirror.com"
   ```

### æ€§èƒ½è°ƒä¼˜

1. **å†…å­˜ä¼˜åŒ–**: é€‚å½“è°ƒæ•´chunk_sizeå’Œbatch_size
2. **é€Ÿåº¦ä¼˜åŒ–**: ä½¿ç”¨GPUåŠ é€Ÿå’Œç¼“å­˜æœºåˆ¶
3. **ç²¾åº¦ä¼˜åŒ–**: è°ƒæ•´ç›¸ä¼¼åº¦é˜ˆå€¼å’Œé‡æ’åºå‚æ•°

## ğŸ“ˆ è¯„ä¼°æŒ‡æ ‡

### æ£€ç´¢è´¨é‡è¯„ä¼°
```python
# è®¡ç®—æ£€ç´¢å‡†ç¡®ç‡
def evaluate_retrieval(queries, ground_truth):
    # å®ç°è¯„ä¼°é€»è¾‘
    pass
```

### ç³»ç»Ÿç›‘æ§
```python
# ç›‘æ§ç³»ç»Ÿæ€§èƒ½
import time
start = time.time()
results = rag.search(query)
print(f"æ£€ç´¢è€—æ—¶: {time.time() - start:.2f}s")
```

---

**RAG Toolkit** - è®©æ™ºèƒ½æ–‡æ¡£æ£€ç´¢æ›´ç®€å• ğŸ“š
